{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "10bbe6360f9659217f9f40455301aa72d6b614a6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXPWRcRHnmkb",
    "outputId": "fb669178-f13a-4297-dc39-9e4fbf57ec55",
    "pycharm": {
     "name": "#%%https://www.kaggle.com/alvations/n-gram-language-model-with-nltk\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
      "Collecting pip\n",
      "  Downloading pip-22.0.3-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 5.2 MB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.1.3\n",
      "    Uninstalling pip-21.1.3:\n",
      "      Successfully uninstalled pip-21.1.3\n",
      "Successfully installed pip-22.0.3\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nltk==3.4\n",
      "  Downloading nltk-3.4.zip (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (1.15.0)\n",
      "Collecting singledispatch\n",
      "  Downloading singledispatch-3.7.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.4-py3-none-any.whl size=1436398 sha256=4d12501737ec2f49fd9aa749003e801296bf5b626ac0be5c899490717e533755\n",
      "  Stored in directory: /root/.cache/pip/wheels/13/b8/81/2349be11dd144dc7b68ab983b58cd2fae353cdc50bbdeb09d0\n",
      "Successfully built nltk\n",
      "Installing collected packages: singledispatch, nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed nltk-3.4 singledispatch-3.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U dill\n",
    "!pip install -U nltk==3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1b213fb0dd5534ce82d6f1c716e9695ba5cf9758",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFkxuxEMnmki",
    "outputId": "74af194d-0c90-4a9d-eb4a-685925500b80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "import nltk\n",
    "import random \n",
    "nltk.download('brown')\n",
    "from nltk.corpus import wordnet \n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S0hWBcaqnmkj"
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i2eQZsAcnmkj"
   },
   "outputs": [],
   "source": [
    "words = [x for x in brown.words(categories='news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tCNnAO23nmkk"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Yw152iXnmkk"
   },
   "outputs": [],
   "source": [
    "sentences = brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CpNHWOmknmkm"
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "a5a1c775bab7cf9c67656d4349d8bfca02a80738",
    "id": "GciSNjiSnmkm"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in brown.sents():\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[(w1, w2)][w3] += 1\n",
    "        \n",
    "#normalizinging the frequency of co-occurence \n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZzWhRFr3nmkn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"file.txt\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6ndnBJYAnmko"
   },
   "outputs": [],
   "source": [
    "list_of_sentences = [i.split(\"*\") for i in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GyOdRmBnmko"
   },
   "outputs": [],
   "source": [
    "import re \n",
    "list_of_sentences = [i[0].split() for i in list_of_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DsOC8LoVnmkp"
   },
   "outputs": [],
   "source": [
    "list1 = [i[2:4] for i in list_of_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "P6RmNb0Unmkq"
   },
   "outputs": [],
   "source": [
    "list_of_correct = [i[1] for i in list_of_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dmuVd5Fpnmkq"
   },
   "outputs": [],
   "source": [
    "sentences = list1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vYuiQmYQnmkr"
   },
   "outputs": [],
   "source": [
    "dict1 = {'the': 0.2857142857142857, 'a': 0.14285714285714285, 'full': 0.07142857142857142, 'failing': 0.07142857142857142, 'as': 0.07142857142857142, 'to': 0.07142857142857142, 'overwhelming': 0.07142857142857142, 'that': 0.07142857142857142, 'incorporation': 0.07142857142857142, 'often': 0.07142857142857142}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EhWWISCjnmkr"
   },
   "outputs": [],
   "source": [
    "dict1 = {key: rank for rank, key in enumerate(sorted(dict1, key=dict1.get, reverse=True), 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjpt7Tfbnmks",
    "outputId": "87725795-ba9c-4058-8fd3-bdbc77348430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'a',\n",
       " 'full',\n",
       " 'failing',\n",
       " 'as',\n",
       " 'to',\n",
       " 'overwhelming',\n",
       " 'that',\n",
       " 'incorporation',\n",
       " 'often']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [x for x in dict1.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "E8IKEaGmnmkt"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams \n",
    "\n",
    "list_of_ngrams = []\n",
    "for i in ([1,2,3,5,10]):\n",
    "    ng = ngrams(brown.words(),i)\n",
    "    list_of_ngrams.append(ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "hGC-FUL7nmkt"
   },
   "outputs": [],
   "source": [
    "# for testing \n",
    "from collections import Counter, defaultdict\n",
    "model_1 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in brown.sents():\n",
    "    for w1 in ngrams(sentence,1, pad_right=True, pad_left=True):\n",
    "        model_1[(w1, w2)][w3] += 1\n",
    "        \n",
    "#normalizinging the frequency of co-occurence \n",
    "for w1_w2 in model_1:\n",
    "    total_count = float(sum(model_1[w1_w2].values()))\n",
    "    for w3 in model_1[w1_w2]:\n",
    "        model_1[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "8zX6CmHDnmkt"
   },
   "outputs": [],
   "source": [
    "# for testing \n",
    "from collections import Counter, defaultdict\n",
    "model_3 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in brown.sents():\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model_3[(w1, w2)][w3] += 1\n",
    "        \n",
    "#normalizinging the frequency of co-occurence \n",
    "for w1_w2 in model_3:\n",
    "    total_count = float(sum(model_3[w1_w2].values()))\n",
    "    for w3 in model_3[w1_w2]:\n",
    "        model_3[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Y-ewqlLBnmkt"
   },
   "outputs": [],
   "source": [
    "# for testing \n",
    "from collections import Counter, defaultdict\n",
    "model_2 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in brown.sents():\n",
    "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model_2[(w1)][w3] += 1\n",
    "        \n",
    "#normalizinging the frequency of co-occurence \n",
    "for w1_w2 in model_2:\n",
    "    total_count = float(sum(model_2[w1_w2].values()))\n",
    "    for w3 in model_2[w1_w2]:\n",
    "        model_2[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Fr0sgyfInmku"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "model_5 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in brown.sents():\n",
    "    for w1, w2, w3, w4,w5 in ngrams(sentence, 5, pad_right=True, pad_left=True):\n",
    "        model_5[(w1,w2, w3, w4)][w5] += 1\n",
    "        \n",
    "#normalizinging the frequency of co-occurence \n",
    "for w1_w2 in model_5:\n",
    "    total_count = float(sum(model_5[w1_w2].values()))\n",
    "    for w3 in model_5[w1_w2]:\n",
    "        model_5[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "K0fvnJCTnmku"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "model_10 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in brown.sents():\n",
    "    for w1, w2, w3, w4,w5, w6, w7, w8,w9, w10 in ngrams(sentence, 10, pad_right=True, pad_left=True):\n",
    "        model_10[(w1,w2, w3, w4,w5, w6, w7, w8,w9,)][w10] += 1\n",
    "        \n",
    "#normalizinging the frequency of co-occurence \n",
    "for w1_w2 in model_5:\n",
    "    total_count = float(sum(model_10[w1_w2].values()))\n",
    "    for w10 in model_10[w1_w2]:\n",
    "        model_10[w1_w2][w10] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1a4o_fdnmkv"
   },
   "outputs": [],
   "source": [
    "len(sentences)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "_Pei9Fodnmkv"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def func0(sentences, model):\n",
    "    list_of_dicts = []\n",
    "    for sentence in sentences:\n",
    "        l = []\n",
    "        dict2 = {}\n",
    "        text = sentence\n",
    "        text_length_initial = len(text)\n",
    "        res = dict(sorted(model[tuple(text[-text_length_initial:])].items(), key = itemgetter(1), reverse = True)[:10])\n",
    "        lista = [x for x in res.keys()]\n",
    "        list_of_dicts.append(lista) \n",
    "    return(list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Hfxm5lIo5qUa"
   },
   "outputs": [],
   "source": [
    "list_of_predicted_model = []\n",
    "models = [model_1, model_2, model_3, model_5, model_10]\n",
    "for model in models:\n",
    "    list_of_predicted_model.append(func0(sentences, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Om9MHcFznmkw",
    "outputId": "14fc3c00-800f-45f0-bb35-67b5387afad6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_predicted_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Wsqbb49Znmkw"
   },
   "outputs": [],
   "source": [
    "qrel = list_of_correct\n",
    "run = list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "bVQzU6efnmkw"
   },
   "outputs": [],
   "source": [
    "def s_and_k(correct_words, predicted_words, k=[1, 5, 10]):\n",
    "    count = []\n",
    "    for i in range(198):\n",
    "        words_candidate = predicted_words[i]\n",
    "        correct_word = correct_words[i]\n",
    "        for j in k:\n",
    "            if correct_word in words_candidate[:j]:\n",
    "                count.append(1)\n",
    "            else:\n",
    "                count.append(0)\n",
    "                pass\n",
    "    return(sum(count) / len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgmS4seu1-UC",
    "outputId": "90893844-c5d2-4a88-e5a8-f4c5b6772f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.015151515151515152, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "means_models_k1 = []\n",
    "for i in range(5):\n",
    "    means_models_k1.append(s_and_k(list_of_correct, list_of_predicted_model[i],k=[1]))\n",
    "print(means_models_k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q02EX-521-Xq",
    "outputId": "5161f2a2-b4e5-45b6-c459-4d7582b90f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.015151515151515152, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "means_models_k5 = []\n",
    "for i in range(5):\n",
    "    means_models_k5.append(s_and_k(list_of_correct, list_of_predicted_model[i],k=[5]))\n",
    "print(means_models_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEtl42HF2fkX",
    "outputId": "009698f8-fd03-4035-b6d8-87fa6e1eb3f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.020202020202020204, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "means_models_k10 = []\n",
    "for i in range(5):\n",
    "    means_models_k10.append(s_and_k(list_of_correct, list_of_predicted_model[i],k=[10]))\n",
    "print(means_models_k10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "976j2dCcnmkw",
    "outputId": "198c7ef8-472e-4b40-e5ed-c7ead7891bc1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytreceval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-7f0fd2a5b863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpytreceval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlist_of_ngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytreceval'"
     ]
    }
   ],
   "source": [
    "#PROBLEM WITH PYTREC_EVAL \n",
    "import pytreceval \n",
    "for model in list_of_ngrams:\n",
    "    qrel = list_of_correct \n",
    "    run = func(sentences,model)\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "        qrel,\n",
    "        {\n",
    "            \"success_1\",\n",
    "            \"success_2\",\n",
    "            \"success_3\",\n",
    "            \"success_4\",\n",
    "            \"success_5\",\n",
    "            \"success_6\",\n",
    "            \"success_7\",\n",
    "            \"success_8\",\n",
    "            \"success_9\",\n",
    "            \"success_10\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    res = evaluator.evaluate(run)\n",
    "    \n",
    "    # printing scores \n",
    "    successes = dict()\n",
    "    for i in range(1, 11):\n",
    "        successes[f\"success_{i}\"] = []\n",
    "\n",
    "    for inc in res:\n",
    "        tmp = res[inc]\n",
    "        for i in range(1, 11):\n",
    "            successes[f\"success_@_{i}\"].append(tmp[f\"success_@_{i}\"])\n",
    "    \n",
    "    successes = dict()\n",
    "    for i in range(1, 11):\n",
    "        successes[f\"success_@_{i}\"] = []\n",
    "\n",
    "    for inc in res:\n",
    "        tmp = res[inc]\n",
    "        for i in range(1, 11):\n",
    "            successes[f\"success_@_{i}\"].append(tmp[f\"success_@_{i}\"])\n",
    "\n",
    "    import numpy as np\n",
    "    for i in range(1, 11):\n",
    "        print(f\"average s@top-{i}: \", np.array(successes[f\"success_@_{i}\"]).mean())  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lm-nltk-Copy2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
